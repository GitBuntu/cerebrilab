# AI Risk Typology

This document outlines a structured typology of risks associated with AI systems.  
It groups risks into four primary categories: Technical, Societal & Ethical, Organizational, and Privacy & Security.

---

## 1. Technical Risks
Risks arising from model behavior, data quality, and system performance.

- **Hallucinations / Inaccuracy**  
  Incorrect, fabricated, or misleading outputs.

- **Robustness Failures**  
  Model instability under perturbations, adversarial prompts, or edge cases.

- **Data Quality Issues**  
  Noisy, biased, incomplete, or outdated training data affecting model behavior.

- **Model Drift**  
  Degradation of performance over time due to changing real‑world conditions.

---

## 2. Societal & Ethical Risks
Risks that affect individuals, communities, or society at large.

- **Bias & Fairness Harms**  
  Unequal treatment or outcomes across demographic groups.

- **Discrimination**  
  Systemic disadvantage or exclusion caused or amplified by AI outputs.

- **Misinformation & Manipulation**  
  Generation or amplification of false, misleading, or harmful narratives.

- **Human Rights Impacts**  
  Violations of dignity, autonomy, or fundamental rights.

- **Social Inequity Amplification**  
  Reinforcement of existing societal disparities.

---

## 3. Organizational Risks
Risks that affect internal operations, governance, and compliance.

- **Compliance Gaps**  
  Misalignment with regulatory, legal, or policy requirements.

- **Operational Failures**  
  Breakdowns in workflows, processes, or system reliability.

- **Governance Weaknesses**  
  Lack of oversight, unclear accountability, or inadequate controls.

- **Insufficient Human Oversight**  
  Over‑reliance on automation without appropriate human review.

---

## 4. Privacy & Security Risks
Risks related to data protection, confidentiality, and system integrity.

- **Data Leakage**  
  Unintended exposure of sensitive or proprietary information.

- **Unauthorized Access**  
  Improper access to systems, models, or datasets.

- **Sensitive Data Exposure**  
  Disclosure of personal or confidential data through model outputs.

- **Security Vulnerabilities**  
  Weaknesses that could be exploited to compromise the system.

---

# Summary

This typology provides a structured foundation for evaluating, mitigating, and governing AI risks across the full system lifecycle. It supports alignment with major frameworks including NIST AI RMF, OECD AI Principles, and the Microsoft Responsible AI Standard.
